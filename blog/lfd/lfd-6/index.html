<!DOCTYPE html>
<html lang="en">

    <head>
    <meta charset="utf-8">
    <title>
         Learning From Data Problem Set 6
        
    </title>
    <!-- TODO: Use a Tera template to get the path to the css? -->
    <link rel="stylesheet" href="/main.css"> 
</head>


    <body>

        <nav>
    <div class="nav-menu">
        
        <a href="/" class="">Home</a>
        
        <a href="/about/" class="">About</a>
        
        <a href="/blog/" class="">Blog</a>
        
        <a href="/dev" class="">Projects</a>
        
    </div>
</nav>


        <section class="section">
            <div class="container">
                
<h1 class="title">
    Learning From Data Problem Set 6
</h1>
<p class="subtitle"><strong>2023-11-02</strong></p>
<p><a href="https://work.caltech.edu/homework/hw6.pdf">PDF of problems</a></p>
<p><a href="https://github.com/lienzhuzhu/lfd">Code Repository</a></p>
<h3 id="1-b">1. [b]</h3>
<p>On average, the smaller hypothesis set will have a higher bias term, which corresponds to deterministic noise. It is true, however, that the smaller hypothesis set would have a decrease in variance that overwhelms the increase in bias.</p>
<h3 id="use-the-following-output-for-problems-2-6">Use the following output for problems 2 - 6</h3>
<pre data-lang="zsh" style="background-color:#2b303b;color:#c0c5ce;" class="language-zsh "><code class="language-zsh" data-lang="zsh"><span style="color:#bf616a;">❯</span><span> python3 hw6/regularization.py
</span><span style="color:#bf616a;">E_in</span><span> with no regularization:     0.02857142857142857
</span><span style="color:#bf616a;">E_out</span><span> with no regularization:    0.084
</span><span style="color:#bf616a;">K</span><span> =</span><span style="color:#bf616a;"> -3</span><span>,  E_in = 0.028571        E_out = 0.080000
</span><span style="color:#bf616a;">K</span><span> =</span><span style="color:#bf616a;"> -2</span><span>,  E_in = 0.028571        E_out = 0.084000
</span><span style="color:#bf616a;">K</span><span> =</span><span style="color:#bf616a;"> -1</span><span>,  E_in = 0.028571        E_out = 0.056000
</span><span style="color:#bf616a;">K</span><span> = 0,   E_in = 0.000000        E_out = 0.092000
</span><span style="color:#bf616a;">K</span><span> = 1,   E_in = 0.057143        E_out = 0.124000
</span><span style="color:#bf616a;">K</span><span> = 2,   E_in = 0.200000        E_out = 0.228000
</span><span style="color:#bf616a;">K</span><span> = 3,   E_in = 0.371429        E_out = 0.436000
</span></code></pre>
<h3 id="2-a">2. [a]</h3>
<p>This is sort of the baseline performance.</p>
<h3 id="3-d">3. [d]</h3>
<p>Small regularization parameter $\lambda$ corresponds to a large $C$, which barely applies any regularization. So, we get similar results to baseline.</p>
<h3 id="4-e">4. [e]</h3>
<p>Too much regularization leads us to underfit the data and target.</p>
<h3 id="5-d">5. [d]</h3>
<p>This is just enough regularization.</p>
<h3 id="6-b">6. [b]</h3>
<p>When $k=-1$, we get an $E_{out}$ of around $0.056$.</p>
<h3 id="7-c">7. [c]</h3>
<p>$$
\begin{aligned}
\mathcal{H}(10, 0, 3) &amp;= w_0L_0 + w_1L_1 + w_2L_2 + 0 + \dots + 0 \\
\mathcal{H}(10, 0, 4) &amp;= w_0L_0 + w_1L_1 + w_2L_2 + w_3L_3 + 0 + \dots + 0 \<br />
\end{aligned}
$$</p>
<p>The intersection of these sets will clearly just be the first 3 terms of $\mathcal{H}(10, 0, 3)$, which is the same as $\mathcal{H}_2$. The union of these is not $\mathcal{H}_4$ because that would require an $L_4$ term to survive, but it perishes in the union.</p>
<h3 id="8-d">8. [d]</h3>
<p>The operation $w_{ij}^{(l)}x_i^{(l-1)}$ is only used in forward propagation and does not appear in backpropagation.</p>
<p>There are $22$ total unique weights in this network and each will be updated during backpropagation. The $w_{ij}^{(l)}\delta_j^{(l)}$ term is used to get $\delta_i^{(l-1)}$ while $x_i^{(l-1)}\delta_j^{(l)}$ terms are used in the weight update step of SGD.</p>
<p>There are $22$ weights and $2$ types of operations of interest, so we would see $44$ of these operations.</p>
<h3 id="9-a">9. [a]</h3>
<p>We can achieve the minimum number of weights, or connections, by making each hidden layer have a single dimension. This would result in $10$ weights between the input layer and the first hidden layer, with $36$ weights from the first hidden layer to the final output layer.</p>
<h3 id="10-e">10. [e]</h3>
<p>If laying all the units in a line yields the minimum, surely the opposite would give us the maximum right? Not exactly. If we have one hidden layer with $36$ units, then we get
$$
10 \times 35 + 36 \times 1 = 350 + 36 = 386 \textrm{ weights}
$$</p>
<p>which is far from what we can get with two hidden layers, each with $18$ units each</p>
<p>$$
10 \times 17 + 18 \times 17 + 18 \times 1 = 170 + 306 + 18 = 494 \textrm{ weights}
$$</p>
<p>So, I brute forced from two layers and reached $510$ with $22$ units in the first hidden layer and $14$ in the second</p>
<p>$$
10\times21 + 22\times13 + 14 = 210 + 286 + 14 = 510 \textrm{ weights}
$$</p>
<p>Note that the bias term has no weights going into it.</p>
<p>I have no idea how to do this analytically with optimization. Luckily, $510$ is the largest answer choice and using quadratic programming we get the following solution:</p>
<pre data-lang="zsh" style="background-color:#2b303b;color:#c0c5ce;" class="language-zsh "><code class="language-zsh" data-lang="zsh"><span style="color:#bf616a;">❯</span><span> python3 hw6/edges.py
</span><span style="color:#bf616a;">L1</span><span> =  22
</span><span style="color:#bf616a;">L2</span><span> =  14
</span><span style="color:#bf616a;">Z</span><span> =  510
</span></code></pre>
<p>Though we get kind of lucky here because this is non linear quadratic programming applied to a linear quadratic programming problem.</p>


            </div>
        </section>

        <!-- MathJAX config -->
        <script>
            MathJax = {
                /* TODO: Experiment with these delimiters */
                tex: {
                    displayMath: [['\\[', '\\]'], ['$$', '$$']],
                    inlineMath: [['\\(', '\\)'], ['$', '$']],
                }
            };
        </script>
        <!-- Load V3.+ -->
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

    </body>


    <footer>
        <div>
            <i class="nf nf-fa-copyright"></i> Lien Zhu 2025
        </div>
    </footer>

</html>
